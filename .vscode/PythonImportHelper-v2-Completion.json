[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "geopandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "geopandas",
        "description": "geopandas",
        "detail": "geopandas",
        "documentation": {}
    },
    {
        "label": "figure",
        "importPath": "bokeh.plotting",
        "description": "bokeh.plotting",
        "isExtraImport": true,
        "detail": "bokeh.plotting",
        "documentation": {}
    },
    {
        "label": "show",
        "importPath": "bokeh.plotting",
        "description": "bokeh.plotting",
        "isExtraImport": true,
        "detail": "bokeh.plotting",
        "documentation": {}
    },
    {
        "label": "plotly.express",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "plotly.express",
        "description": "plotly.express",
        "detail": "plotly.express",
        "documentation": {}
    },
    {
        "label": "pycountry",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pycountry",
        "description": "pycountry",
        "detail": "pycountry",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "directory = './assignment1 data'\n# List of file names based on the naming pattern\nfile_names = [f'stats_crashes_{year}{month:02d}_overview.csv' for year in [2021] for month in range(6,13)]\n# Initialize an empty list to store DataFrames\ndataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "file_names",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "file_names = [f'stats_crashes_{year}{month:02d}_overview.csv' for year in [2021] for month in range(6,13)]\n# Initialize an empty list to store DataFrames\ndataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails\n        df = pd.read_csv(file_path, encoding='utf-16')\n        dataframes.append(df)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "dataframes",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "dataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails\n        df = pd.read_csv(file_path, encoding='utf-16')\n        dataframes.append(df)\n    except UnicodeDecodeError:\n        # Fall back to UTF-8 or another encoding as needed",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "crashes_merged",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "crashes_merged = pd.concat(dataframes, ignore_index=True)\n# Convert the 'Date' column to datetime format\ncrashes_merged['Date'] = pd.to_datetime(crashes_merged['Date'])\n# Sort the DataFrame by the 'Date' column\ncrashes_merged = crashes_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'crashes_merged.csv')\ncrashes_merged.to_csv(merged_file_path, index=False)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "crashes_merged['Date']",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "crashes_merged['Date'] = pd.to_datetime(crashes_merged['Date'])\n# Sort the DataFrame by the 'Date' column\ncrashes_merged = crashes_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'crashes_merged.csv')\ncrashes_merged.to_csv(merged_file_path, index=False)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "crashes_merged",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "crashes_merged = crashes_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'crashes_merged.csv')\ncrashes_merged.to_csv(merged_file_path, index=False)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "merged_file_path",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "merged_file_path = os.path.join(\"./merged_data\", 'crashes_merged.csv')\ncrashes_merged.to_csv(merged_file_path, index=False)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "directory = './merged_data'\nfile_name = ['sales_merged.csv']\nfor file in file_name:\n    if file.endswith('merged.csv'):  # Ensure to only include processed files\n        file_path = os.path.join(directory, file)\n        df = pd.read_csv(file_path)\n#The following lines describe a KPI based on Sales volume\n# Convert 'Date' to datetime object\ndf['Date'] = pd.to_datetime(df['Date'])\n# Extract date attributes into new columns",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "file_name",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "file_name = ['sales_merged.csv']\nfor file in file_name:\n    if file.endswith('merged.csv'):  # Ensure to only include processed files\n        file_path = os.path.join(directory, file)\n        df = pd.read_csv(file_path)\n#The following lines describe a KPI based on Sales volume\n# Convert 'Date' to datetime object\ndf['Date'] = pd.to_datetime(df['Date'])\n# Extract date attributes into new columns\ndf['Year'] = df['Date'].dt.year",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "df['Date']",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "df['Date'] = pd.to_datetime(df['Date'])\n# Extract date attributes into new columns\ndf['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.month\ndf['Day'] = df['Date'].dt.day\n#The data is grouped by month \n#This line calculates the average amount of money per transaction per month\naverage_amount_by_month = df.groupby('Month')['Amount (Merchant Currency)'].mean()\nprint(average_amount_by_month)\n#This line calculates the monthly revenue and growth",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "df['Year']",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "df['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.month\ndf['Day'] = df['Date'].dt.day\n#The data is grouped by month \n#This line calculates the average amount of money per transaction per month\naverage_amount_by_month = df.groupby('Month')['Amount (Merchant Currency)'].mean()\nprint(average_amount_by_month)\n#This line calculates the monthly revenue and growth\nmonthly_revenue = df.groupby('Month')['Amount (Merchant Currency)'].sum()\n#print(monthly_revenue)",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "df['Month']",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "df['Month'] = df['Date'].dt.month\ndf['Day'] = df['Date'].dt.day\n#The data is grouped by month \n#This line calculates the average amount of money per transaction per month\naverage_amount_by_month = df.groupby('Month')['Amount (Merchant Currency)'].mean()\nprint(average_amount_by_month)\n#This line calculates the monthly revenue and growth\nmonthly_revenue = df.groupby('Month')['Amount (Merchant Currency)'].sum()\n#print(monthly_revenue)\nmonthly_transaction_count = df.groupby('Month')['Transaction ID'].count()",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "df['Day']",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "df['Day'] = df['Date'].dt.day\n#The data is grouped by month \n#This line calculates the average amount of money per transaction per month\naverage_amount_by_month = df.groupby('Month')['Amount (Merchant Currency)'].mean()\nprint(average_amount_by_month)\n#This line calculates the monthly revenue and growth\nmonthly_revenue = df.groupby('Month')['Amount (Merchant Currency)'].sum()\n#print(monthly_revenue)\nmonthly_transaction_count = df.groupby('Month')['Transaction ID'].count()\n# Calculate Monthly Growth Percentage",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "average_amount_by_month",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "average_amount_by_month = df.groupby('Month')['Amount (Merchant Currency)'].mean()\nprint(average_amount_by_month)\n#This line calculates the monthly revenue and growth\nmonthly_revenue = df.groupby('Month')['Amount (Merchant Currency)'].sum()\n#print(monthly_revenue)\nmonthly_transaction_count = df.groupby('Month')['Transaction ID'].count()\n# Calculate Monthly Growth Percentage\nmonthly_revenue_growth = monthly_revenue.pct_change() * 100\nmonthly_transaction_count_growth = monthly_transaction_count.pct_change() * 100\n# Export the x-axis (Month)",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "monthly_revenue",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "monthly_revenue = df.groupby('Month')['Amount (Merchant Currency)'].sum()\n#print(monthly_revenue)\nmonthly_transaction_count = df.groupby('Month')['Transaction ID'].count()\n# Calculate Monthly Growth Percentage\nmonthly_revenue_growth = monthly_revenue.pct_change() * 100\nmonthly_transaction_count_growth = monthly_transaction_count.pct_change() * 100\n# Export the x-axis (Month)\ndf[['Month']].to_csv('month_data.csv', index=False)\n# Export monthly_revenue_growth as its own CSV\nmonthly_revenue_growth.to_frame(name='Monthly Revenue Growth (%)').reset_index(drop=True).to_csv('monthly_revenue_growth.csv', index=False)",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "monthly_transaction_count",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "monthly_transaction_count = df.groupby('Month')['Transaction ID'].count()\n# Calculate Monthly Growth Percentage\nmonthly_revenue_growth = monthly_revenue.pct_change() * 100\nmonthly_transaction_count_growth = monthly_transaction_count.pct_change() * 100\n# Export the x-axis (Month)\ndf[['Month']].to_csv('month_data.csv', index=False)\n# Export monthly_revenue_growth as its own CSV\nmonthly_revenue_growth.to_frame(name='Monthly Revenue Growth (%)').reset_index(drop=True).to_csv('monthly_revenue_growth.csv', index=False)\n# Export monthly_transaction_count_growth as its own CSV\nmonthly_transaction_count_growth.to_frame(name='Monthly Transaction Count Growth (%)').reset_index(drop=True).to_csv('monthly_transaction_count_growth.csv', index=False)",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "monthly_revenue_growth",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "monthly_revenue_growth = monthly_revenue.pct_change() * 100\nmonthly_transaction_count_growth = monthly_transaction_count.pct_change() * 100\n# Export the x-axis (Month)\ndf[['Month']].to_csv('month_data.csv', index=False)\n# Export monthly_revenue_growth as its own CSV\nmonthly_revenue_growth.to_frame(name='Monthly Revenue Growth (%)').reset_index(drop=True).to_csv('monthly_revenue_growth.csv', index=False)\n# Export monthly_transaction_count_growth as its own CSV\nmonthly_transaction_count_growth.to_frame(name='Monthly Transaction Count Growth (%)').reset_index(drop=True).to_csv('monthly_transaction_count_growth.csv', index=False)\n# Create a Plot\nfig, ax1 = plt.subplots(figsize=(10, 6))",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "monthly_transaction_count_growth",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "monthly_transaction_count_growth = monthly_transaction_count.pct_change() * 100\n# Export the x-axis (Month)\ndf[['Month']].to_csv('month_data.csv', index=False)\n# Export monthly_revenue_growth as its own CSV\nmonthly_revenue_growth.to_frame(name='Monthly Revenue Growth (%)').reset_index(drop=True).to_csv('monthly_revenue_growth.csv', index=False)\n# Export monthly_transaction_count_growth as its own CSV\nmonthly_transaction_count_growth.to_frame(name='Monthly Transaction Count Growth (%)').reset_index(drop=True).to_csv('monthly_transaction_count_growth.csv', index=False)\n# Create a Plot\nfig, ax1 = plt.subplots(figsize=(10, 6))\n# Plot Monthly Revenue Growth",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "ax2",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "ax2 = ax1.twinx()\nax2.plot(monthly_transaction_count_growth, color='green', marker='s', label='Transaction Count Growth (%)')\nax2.set_ylabel('Transaction Count Growth (%)', color='green')\nax2.tick_params('y', colors='green')\nax2.legend(loc='upper right')\nplt.title('Monthly Growth Percentage: Revenue and Transaction Count')\nplt.show()\n# Filter rows where 'Amount' is higher than 10\nfiltered_data = df[df['Amount (Merchant Currency)'] > 10]\n# Display the filtered DataFrame",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "filtered_data",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "filtered_data = df[df['Amount (Merchant Currency)'] > 10]\n# Display the filtered DataFrame\nprint(filtered_data)\n#KPI that shows Product Rate per month\nmonthly_grouped_data = df.groupby('Month')\n# Step 2: Group by 'Product Title' within each month and count transactions\nmonthly_transaction_count_per_product = monthly_grouped_data.apply(lambda x: x.groupby('Product Title')['Transaction ID'].count().reset_index(name='Transaction_Count'))\n# Display the result\nprint(monthly_transaction_count_per_product)\nfig, ax = plt.subplots(figsize=(10, 5))",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "monthly_grouped_data",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "monthly_grouped_data = df.groupby('Month')\n# Step 2: Group by 'Product Title' within each month and count transactions\nmonthly_transaction_count_per_product = monthly_grouped_data.apply(lambda x: x.groupby('Product Title')['Transaction ID'].count().reset_index(name='Transaction_Count'))\n# Display the result\nprint(monthly_transaction_count_per_product)\nfig, ax = plt.subplots(figsize=(10, 5))\ncolor_mapping = {'Product Title 1': 'pink', 'Product Title 2': 'blue'} \ncolor_mapping1=[color_mapping.get(title, 'gray') for title in monthly_transaction_count_per_product['Product Title']]\nsns.barplot(x='Month', y='Transaction_Count', hue='Product Title', data=monthly_transaction_count_per_product, palette = ['blue', 'pink'], ax=ax)\n# Display the result",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "monthly_transaction_count_per_product",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "monthly_transaction_count_per_product = monthly_grouped_data.apply(lambda x: x.groupby('Product Title')['Transaction ID'].count().reset_index(name='Transaction_Count'))\n# Display the result\nprint(monthly_transaction_count_per_product)\nfig, ax = plt.subplots(figsize=(10, 5))\ncolor_mapping = {'Product Title 1': 'pink', 'Product Title 2': 'blue'} \ncolor_mapping1=[color_mapping.get(title, 'gray') for title in monthly_transaction_count_per_product['Product Title']]\nsns.barplot(x='Month', y='Transaction_Count', hue='Product Title', data=monthly_transaction_count_per_product, palette = ['blue', 'pink'], ax=ax)\n# Display the result\nplt.title('Monthly Transactions per Product Type')\nplt.xlabel('Month')",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "color_mapping",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "color_mapping = {'Product Title 1': 'pink', 'Product Title 2': 'blue'} \ncolor_mapping1=[color_mapping.get(title, 'gray') for title in monthly_transaction_count_per_product['Product Title']]\nsns.barplot(x='Month', y='Transaction_Count', hue='Product Title', data=monthly_transaction_count_per_product, palette = ['blue', 'pink'], ax=ax)\n# Display the result\nplt.title('Monthly Transactions per Product Type')\nplt.xlabel('Month')\nplt.ylabel('Transactions')\nplt.show()\n#KPI that shows Product Rate per month\nmonthly_grouped_data = df.groupby('Month')",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "monthly_grouped_data",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "monthly_grouped_data = df.groupby('Month')\n# Step 2: Group by 'Product Title' within each month and count transactions\nmonthly_transaction_count_per_sku = monthly_grouped_data.apply(lambda x: x.groupby('SKU ID')['Transaction ID'].count().reset_index(name='Transaction_Count'))\n# Display the result\nprint(monthly_transaction_count_per_sku)\nfig, ax = plt.subplots(figsize=(10, 5))\ncolor_mapping = {'SKU ID 0': 'pink', 'SKU ID 1': 'blue'} \ncolor_mapping1=[color_mapping.get(title, 'gray') for title in monthly_transaction_count_per_sku['SKU ID']]\nsns.barplot(x='Month', y='Transaction_Count', hue='SKU ID', data=monthly_transaction_count_per_sku, palette = ['blue', 'pink'], ax=ax)\n# Display the result",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "monthly_transaction_count_per_sku",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "monthly_transaction_count_per_sku = monthly_grouped_data.apply(lambda x: x.groupby('SKU ID')['Transaction ID'].count().reset_index(name='Transaction_Count'))\n# Display the result\nprint(monthly_transaction_count_per_sku)\nfig, ax = plt.subplots(figsize=(10, 5))\ncolor_mapping = {'SKU ID 0': 'pink', 'SKU ID 1': 'blue'} \ncolor_mapping1=[color_mapping.get(title, 'gray') for title in monthly_transaction_count_per_sku['SKU ID']]\nsns.barplot(x='Month', y='Transaction_Count', hue='SKU ID', data=monthly_transaction_count_per_sku, palette = ['blue', 'pink'], ax=ax)\n# Display the result\nplt.title('Monthly Transactions per SKU ID')\nplt.xlabel('Month')",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "color_mapping",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "color_mapping = {'SKU ID 0': 'pink', 'SKU ID 1': 'blue'} \ncolor_mapping1=[color_mapping.get(title, 'gray') for title in monthly_transaction_count_per_sku['SKU ID']]\nsns.barplot(x='Month', y='Transaction_Count', hue='SKU ID', data=monthly_transaction_count_per_sku, palette = ['blue', 'pink'], ax=ax)\n# Display the result\nplt.title('Monthly Transactions per SKU ID')\nplt.xlabel('Month')\nplt.ylabel('Transactions')\nplt.show()\n# Create a new column 'weekday' containing the weekday for each date (0 = Monday, 1 = Tuesday, ..., 6 = Sunday)\ndf['Weekday'] = df['Date'].dt.weekday",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "df['Weekday']",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "df['Weekday'] = df['Date'].dt.weekday\ndf['Month'] = df['Date'].dt.month\n# Display the DataFrame with the new 'weekday' column\nprint(df[['Date', 'Weekday']])\n# Create a pivot table for the heatmap\nheatmap_data = df.pivot_table(index = 'Month', columns='Weekday', values='Transaction ID', aggfunc='count')\n# Create a Plot\nfig, ax = plt.subplots(figsize=(12, 8))\n# Use seaborn to create a heatmap\nsns.heatmap(heatmap_data, cmap='Blues', annot=True, fmt='g', linewidths=.5, cbar_kws={'label': 'Transaction Count'})",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "df['Month']",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "df['Month'] = df['Date'].dt.month\n# Display the DataFrame with the new 'weekday' column\nprint(df[['Date', 'Weekday']])\n# Create a pivot table for the heatmap\nheatmap_data = df.pivot_table(index = 'Month', columns='Weekday', values='Transaction ID', aggfunc='count')\n# Create a Plot\nfig, ax = plt.subplots(figsize=(12, 8))\n# Use seaborn to create a heatmap\nsns.heatmap(heatmap_data, cmap='Blues', annot=True, fmt='g', linewidths=.5, cbar_kws={'label': 'Transaction Count'})\n# Display the result",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "heatmap_data",
        "kind": 5,
        "importPath": "KPI",
        "description": "KPI",
        "peekOfCode": "heatmap_data = df.pivot_table(index = 'Month', columns='Weekday', values='Transaction ID', aggfunc='count')\n# Create a Plot\nfig, ax = plt.subplots(figsize=(12, 8))\n# Use seaborn to create a heatmap\nsns.heatmap(heatmap_data, cmap='Blues', annot=True, fmt='g', linewidths=.5, cbar_kws={'label': 'Transaction Count'})\n# Display the result\nplt.title('Heatmap of Transaction Count Based on Day of the Week and Time of the Day')\nplt.xlabel('Day of the Week')\nplt.ylabel('Month of the Week')\nplt.show()",
        "detail": "KPI",
        "documentation": {}
    },
    {
        "label": "delete_columns",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def delete_columns(df, columns_to_delete):\n    # Check if the specified columns exist in the DataFrame before attempting deletion\n    existing_columns = set(df.columns)\n    columns_to_delete = [col for col in columns_to_delete if col in existing_columns]\n    if columns_to_delete:\n        df.drop(columns=columns_to_delete, inplace=True)\n        print(\"Specified columns deleted successfully.\")\n    else:\n        print(\"No specified columns found for deletion.\")\n    return df",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "map_currency_conversion_rates",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def map_currency_conversion_rates(df):\n    global currency_conversion_to_euro, available_currencies\n    required_columns = [\n        'Buyer Currency', \n        'Currency Conversion Rate', \n        'Merchant Currency'\n    ]\n    # Check if all required columns are in the DataFrame\n    if all(column in df.columns for column in required_columns) and 'EUR' in df['Merchant Currency'].unique():\n        # Iterate over each row in the DataFrame",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "standardize_column_names",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def standardize_column_names(df, column_mapping):\n    standardized_columns = {}\n    for col in df.columns:\n        standardized_name = column_mapping.get(col, col)  # Get the standardized name if it exists\n        standardized_columns[col] = standardized_name\n    df.rename(columns=standardized_columns, inplace=True)\n    return df\ndef filter_function(file_path, product_id, column_mapping):\n    dtype = {'Amount (Merchant Currency)': float}\n    df = pd.read_csv(file_path, dtype=dtype)",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "filter_function",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def filter_function(file_path, product_id, column_mapping):\n    dtype = {'Amount (Merchant Currency)': float}\n    df = pd.read_csv(file_path, dtype=dtype)\n    df = standardize_column_names(df, column_mapping)  # Standardize column names here\n    filtered_df = df[df['Product ID'].str.contains(product_id)]  # Use the standardized column name\n    return filtered_df\ndef process_data(df):\n    df['Date'] = df['Date'].apply(parser.parse)  # Make sure 'Date' is the standardized column name\n    # Additional preprocessing steps can be added here\n    return df",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "process_data",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def process_data(df):\n    df['Date'] = df['Date'].apply(parser.parse)  # Make sure 'Date' is the standardized column name\n    # Additional preprocessing steps can be added here\n    return df\ndirectory = '.\\\\assignment1 data'\nproduct_id = 'com.vansteinengroentjes.apps.ddfive'\ncolumn_mapping = {\n    'Description': 'Transaction ID',\n    'Order Number': 'Transaction ID',\n    'Transaction Date': 'Date',",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "convert_charged_amount",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def convert_charged_amount(df, currency_conversion_to_euro):\n    result_df = pd.DataFrame()  # Initialize an empty DataFrame for the results\n    for index, row in df.iterrows():\n        currency = row['Currency of Sale']\n        if pd.isnull(currency):  # Check for NaN currency\n            print(f\"Row with index {index} has NaN currency. Skipping conversion.\")\n            result_df = pd.concat([result_df, pd.DataFrame([row])], ignore_index=True)\n            continue  # Skip the rest of the loop for this row\n        # Check if the currency is in the available currencies set\n        if currency in available_currencies:",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merge_columns",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def merge_columns(df):\n    # Check if both columns exist in the DataFrame before attempting merge\n    if 'Charged Amount' in df.columns and 'Amount (Merchant Currency)' in df.columns:\n        df['Amount (Merchant Currency)'] = df.apply(lambda row: row['Charged Amount'] if pd.notna(row['Charged Amount']) else row['Amount (Merchant Currency)'], axis=1)\n        print(\"Columns merged successfully.\")\n    if 'Financial Status' in df.columns and 'Transaction Type' in df.columns:\n        df['Transaction Type'] = df.apply(lambda row: 'Charge' if row['Financial Status'] == 'Charged' else row['Transaction Type'], axis=1)\n        print(\"Columns merged successfully.\")\n    else:\n        print(\"Required columns for merging are not present.\")",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "filter_transaction_type",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")\n    else:\n        print(\"Transaction Type column not found. Skipping filtering.\")\n    return df\n# # Before saving the merged file, apply the filter function\nmerged_df = filter_transaction_type(merged_df)\n# Save the merged DataFrame to a new CSV file",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "available_currencies",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "available_currencies = set()\ncurrency_conversion_to_euro = {}\ndef map_currency_conversion_rates(df):\n    global currency_conversion_to_euro, available_currencies\n    required_columns = [\n        'Buyer Currency', \n        'Currency Conversion Rate', \n        'Merchant Currency'\n    ]\n    # Check if all required columns are in the DataFrame",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "currency_conversion_to_euro",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "currency_conversion_to_euro = {}\ndef map_currency_conversion_rates(df):\n    global currency_conversion_to_euro, available_currencies\n    required_columns = [\n        'Buyer Currency', \n        'Currency Conversion Rate', \n        'Merchant Currency'\n    ]\n    # Check if all required columns are in the DataFrame\n    if all(column in df.columns for column in required_columns) and 'EUR' in df['Merchant Currency'].unique():",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "directory = '.\\\\assignment1 data'\nproduct_id = 'com.vansteinengroentjes.apps.ddfive'\ncolumn_mapping = {\n    'Description': 'Transaction ID',\n    'Order Number': 'Transaction ID',\n    'Transaction Date': 'Date',\n    'Order Charged Date': 'Date',\n    'Transaction Time': 'Timestamp',\n    'Order Charged Timestamp': 'Timestamp',\n    'Tax Type': 'Tax Status',",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "product_id",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "product_id = 'com.vansteinengroentjes.apps.ddfive'\ncolumn_mapping = {\n    'Description': 'Transaction ID',\n    'Order Number': 'Transaction ID',\n    'Transaction Date': 'Date',\n    'Order Charged Date': 'Date',\n    'Transaction Time': 'Timestamp',\n    'Order Charged Timestamp': 'Timestamp',\n    'Tax Type': 'Tax Status',\n    'Product id': 'Product ID',",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "column_mapping",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "column_mapping = {\n    'Description': 'Transaction ID',\n    'Order Number': 'Transaction ID',\n    'Transaction Date': 'Date',\n    'Order Charged Date': 'Date',\n    'Transaction Time': 'Timestamp',\n    'Order Charged Timestamp': 'Timestamp',\n    'Tax Type': 'Tax Status',\n    'Product id': 'Product ID',\n    'Product ID': 'Product ID',",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "processed_files",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "processed_files = os.listdir(save_directory)\nall_dfs = []  # List to store all DataFrames\nfor file in processed_files:\n    if file.endswith('_processed.csv'):  # Ensure to only include processed files\n        file_path = os.path.join(save_directory, file)\n        df = pd.read_csv(file_path)\n        all_dfs.append(df)\n# Concatenate all DataFrames in the list\nmerged_df = pd.concat(all_dfs, ignore_index=True)\ndef convert_charged_amount(df, currency_conversion_to_euro):",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "all_dfs",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "all_dfs = []  # List to store all DataFrames\nfor file in processed_files:\n    if file.endswith('_processed.csv'):  # Ensure to only include processed files\n        file_path = os.path.join(save_directory, file)\n        df = pd.read_csv(file_path)\n        all_dfs.append(df)\n# Concatenate all DataFrames in the list\nmerged_df = pd.concat(all_dfs, ignore_index=True)\ndef convert_charged_amount(df, currency_conversion_to_euro):\n    result_df = pd.DataFrame()  # Initialize an empty DataFrame for the results",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_df = pd.concat(all_dfs, ignore_index=True)\ndef convert_charged_amount(df, currency_conversion_to_euro):\n    result_df = pd.DataFrame()  # Initialize an empty DataFrame for the results\n    for index, row in df.iterrows():\n        currency = row['Currency of Sale']\n        if pd.isnull(currency):  # Check for NaN currency\n            print(f\"Row with index {index} has NaN currency. Skipping conversion.\")\n            result_df = pd.concat([result_df, pd.DataFrame([row])], ignore_index=True)\n            continue  # Skip the rest of the loop for this row\n        # Check if the currency is in the available currencies set",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "pre_conversion_file_path",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "pre_conversion_file_path = os.path.join(\".\\\\processed_data\", 'sales_pre_conversion_merged.csv')\nmerged_df.to_csv(pre_conversion_file_path, index=False)\nprint(f'Pre-conversion merged file saved to: {pre_conversion_file_path}')\nprint(\"Currency conversion rates:\", currency_conversion_to_euro)\nif currency_conversion_to_euro:\n    merged_df = convert_charged_amount(merged_df, currency_conversion_to_euro)\nmerged_df = merge_columns(merged_df)\ncolumns_to_delete = ['Timestamp', 'Tax Status', 'Refund Type', 'Financial Status','Product Type','Hardware', 'Buyer State', 'Buyer Currency', 'Amount (Buyer Currency)','Currency Conversion Rate', 'Merchant Currency', 'Base Plan ID', 'Offer ID','Device Model',\t'Currency of Sale'\t,'Item Price',\t'Taxes Collected','Charged Amount',\t'City of Buyer',\t'State of Buyer'  ]  # Specify columns to delete here  # noqa: E999\nmerged_df = delete_columns(merged_df, columns_to_delete)  # Update merged_df with the result of delete_columns\ndef filter_transaction_type(df):",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_df = merge_columns(merged_df)\ncolumns_to_delete = ['Timestamp', 'Tax Status', 'Refund Type', 'Financial Status','Product Type','Hardware', 'Buyer State', 'Buyer Currency', 'Amount (Buyer Currency)','Currency Conversion Rate', 'Merchant Currency', 'Base Plan ID', 'Offer ID','Device Model',\t'Currency of Sale'\t,'Item Price',\t'Taxes Collected','Charged Amount',\t'City of Buyer',\t'State of Buyer'  ]  # Specify columns to delete here  # noqa: E999\nmerged_df = delete_columns(merged_df, columns_to_delete)  # Update merged_df with the result of delete_columns\ndef filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")\n    else:\n        print(\"Transaction Type column not found. Skipping filtering.\")\n    return df",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "columns_to_delete",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "columns_to_delete = ['Timestamp', 'Tax Status', 'Refund Type', 'Financial Status','Product Type','Hardware', 'Buyer State', 'Buyer Currency', 'Amount (Buyer Currency)','Currency Conversion Rate', 'Merchant Currency', 'Base Plan ID', 'Offer ID','Device Model',\t'Currency of Sale'\t,'Item Price',\t'Taxes Collected','Charged Amount',\t'City of Buyer',\t'State of Buyer'  ]  # Specify columns to delete here  # noqa: E999\nmerged_df = delete_columns(merged_df, columns_to_delete)  # Update merged_df with the result of delete_columns\ndef filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")\n    else:\n        print(\"Transaction Type column not found. Skipping filtering.\")\n    return df\n# # Before saving the merged file, apply the filter function",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_df = delete_columns(merged_df, columns_to_delete)  # Update merged_df with the result of delete_columns\ndef filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")\n    else:\n        print(\"Transaction Type column not found. Skipping filtering.\")\n    return df\n# # Before saving the merged file, apply the filter function\nmerged_df = filter_transaction_type(merged_df)",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_df = filter_transaction_type(merged_df)\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\".\\\\merged_data\", 'sales_merged.csv')\nmerged_df.to_csv(merged_file_path, index=False)\nprint(f'Merged file saved to: {merged_file_path}')",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_file_path",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_file_path = os.path.join(\".\\\\merged_data\", 'sales_merged.csv')\nmerged_df.to_csv(merged_file_path, index=False)\nprint(f'Merged file saved to: {merged_file_path}')",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "directory = './assignment1 data'\n# List of file names based on the naming pattern\nfile_names = [f'stats_ratings_{year}{month:02d}_country.csv' for year in [2021] for month in range(6,13)]\n# Initialize an empty list to store DataFrames\ndataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "file_names",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "file_names = [f'stats_ratings_{year}{month:02d}_country.csv' for year in [2021] for month in range(6,13)]\n# Initialize an empty list to store DataFrames\ndataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails\n        df = pd.read_csv(file_path, encoding='utf-16')\n        dataframes.append(df)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "dataframes",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "dataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails\n        df = pd.read_csv(file_path, encoding='utf-16')\n        dataframes.append(df)\n    except UnicodeDecodeError:\n        # Fall back to UTF-8 or another encoding as needed",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "country_stats_merged",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "country_stats_merged = pd.concat(dataframes, ignore_index=True)\n# Convert the 'Date' column to datetime format\ncountry_stats_merged['Date'] = pd.to_datetime(country_stats_merged['Date'])\n# Sort the DataFrame by the 'Date' column\ncountry_stats_merged = country_stats_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'country_stats_merged.csv')\ncountry_stats_merged.to_csv(merged_file_path, index=False)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "country_stats_merged['Date']",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "country_stats_merged['Date'] = pd.to_datetime(country_stats_merged['Date'])\n# Sort the DataFrame by the 'Date' column\ncountry_stats_merged = country_stats_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'country_stats_merged.csv')\ncountry_stats_merged.to_csv(merged_file_path, index=False)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "country_stats_merged",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "country_stats_merged = country_stats_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'country_stats_merged.csv')\ncountry_stats_merged.to_csv(merged_file_path, index=False)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "merged_file_path",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "merged_file_path = os.path.join(\"./merged_data\", 'country_stats_merged.csv')\ncountry_stats_merged.to_csv(merged_file_path, index=False)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "directory = './merged_data'\n# List of CSV files containing country statistics and sales data\ncountry_stats_file = ['country_stats_merged.csv']\nsales_file = ['sales_merged.csv']\n# Loop through each country statistics file\nfor file in country_stats_file:\n    # Check if the file name ends with 'merged.csv'\n    if file.endswith('merged.csv'):\n        # Construct the file path\n        file_path = os.path.join(directory, file)",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "country_stats_file",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "country_stats_file = ['country_stats_merged.csv']\nsales_file = ['sales_merged.csv']\n# Loop through each country statistics file\nfor file in country_stats_file:\n    # Check if the file name ends with 'merged.csv'\n    if file.endswith('merged.csv'):\n        # Construct the file path\n        file_path = os.path.join(directory, file)\n        # Read the CSV file into a DataFrame\n        country_stats_df = pd.read_csv(file_path)",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "sales_file",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "sales_file = ['sales_merged.csv']\n# Loop through each country statistics file\nfor file in country_stats_file:\n    # Check if the file name ends with 'merged.csv'\n    if file.endswith('merged.csv'):\n        # Construct the file path\n        file_path = os.path.join(directory, file)\n        # Read the CSV file into a DataFrame\n        country_stats_df = pd.read_csv(file_path)\nfor file in sales_file:",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "country_code_mapping",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "country_code_mapping = {country.alpha_2: country.alpha_3 for country in pycountry.countries}\n# Map the codes in your DataFrame using the dictionary\ncountry_stats_df['Country'] = country_stats_df['Country'].map(country_code_mapping)\nsales_df['Country'] = sales_df['Country of Buyer'].map(country_code_mapping)\n# Convert the 'Date' column to datetime format\ncountry_stats_df['Date'] = pd.to_datetime(country_stats_df['Date'])\n# Average rating per country per day\navg_rating_per_country_per_day_fig = px.scatter_geo(country_stats_df,\n                     locations=\"Country\",  # Assumes 'Country' contains ISO country codes\n                     size=\"Total Average Rating\",  # Bubble size based on total average rating",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "country_stats_df['Country']",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "country_stats_df['Country'] = country_stats_df['Country'].map(country_code_mapping)\nsales_df['Country'] = sales_df['Country of Buyer'].map(country_code_mapping)\n# Convert the 'Date' column to datetime format\ncountry_stats_df['Date'] = pd.to_datetime(country_stats_df['Date'])\n# Average rating per country per day\navg_rating_per_country_per_day_fig = px.scatter_geo(country_stats_df,\n                     locations=\"Country\",  # Assumes 'Country' contains ISO country codes\n                     size=\"Total Average Rating\",  # Bubble size based on total average rating\n                     color=\"Total Average Rating\",  # Color based on total average rating\n                     animation_frame=country_stats_df['Date'].dt.strftime('%Y-%m-%d'),",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "sales_df['Country']",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "sales_df['Country'] = sales_df['Country of Buyer'].map(country_code_mapping)\n# Convert the 'Date' column to datetime format\ncountry_stats_df['Date'] = pd.to_datetime(country_stats_df['Date'])\n# Average rating per country per day\navg_rating_per_country_per_day_fig = px.scatter_geo(country_stats_df,\n                     locations=\"Country\",  # Assumes 'Country' contains ISO country codes\n                     size=\"Total Average Rating\",  # Bubble size based on total average rating\n                     color=\"Total Average Rating\",  # Color based on total average rating\n                     animation_frame=country_stats_df['Date'].dt.strftime('%Y-%m-%d'),\n                     hover_name=\"Country\",  # Tooltip shows country name",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "country_stats_df['Date']",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "country_stats_df['Date'] = pd.to_datetime(country_stats_df['Date'])\n# Average rating per country per day\navg_rating_per_country_per_day_fig = px.scatter_geo(country_stats_df,\n                     locations=\"Country\",  # Assumes 'Country' contains ISO country codes\n                     size=\"Total Average Rating\",  # Bubble size based on total average rating\n                     color=\"Total Average Rating\",  # Color based on total average rating\n                     animation_frame=country_stats_df['Date'].dt.strftime('%Y-%m-%d'),\n                     hover_name=\"Country\",  # Tooltip shows country name\n                     projection=\"natural earth\",\n                     title=\"Total Average Rating by Country\",",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "avg_rating_per_country_per_day_fig",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "avg_rating_per_country_per_day_fig = px.scatter_geo(country_stats_df,\n                     locations=\"Country\",  # Assumes 'Country' contains ISO country codes\n                     size=\"Total Average Rating\",  # Bubble size based on total average rating\n                     color=\"Total Average Rating\",  # Color based on total average rating\n                     animation_frame=country_stats_df['Date'].dt.strftime('%Y-%m-%d'),\n                     hover_name=\"Country\",  # Tooltip shows country name\n                     projection=\"natural earth\",\n                     title=\"Total Average Rating by Country\",\n                     color_continuous_scale=\"viridis\",  # Vibrant color scale\n                     range_color=[1,5])  # Range covering the full scope of ratings",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "sales_by_country",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "sales_by_country = sales_df.groupby('Country')['Amount (Merchant Currency)'].sum().reset_index()\nsales_map_fig = px.choropleth(sales_by_country,\n                              locations=\"Country\",\n                              color=\"Amount (Merchant Currency)\",\n                              hover_name=\"Country\",\n                              projection=\"natural earth\",\n                              title=\"Total Sales Volume by Country\",\n                              color_continuous_scale=\"viridis\")  # Adjust color scale as desired\n# Show the figure\nsales_map_fig.show()",
        "detail": "visualisationMai",
        "documentation": {}
    },
    {
        "label": "sales_map_fig",
        "kind": 5,
        "importPath": "visualisationMai",
        "description": "visualisationMai",
        "peekOfCode": "sales_map_fig = px.choropleth(sales_by_country,\n                              locations=\"Country\",\n                              color=\"Amount (Merchant Currency)\",\n                              hover_name=\"Country\",\n                              projection=\"natural earth\",\n                              title=\"Total Sales Volume by Country\",\n                              color_continuous_scale=\"viridis\")  # Adjust color scale as desired\n# Show the figure\nsales_map_fig.show()",
        "detail": "visualisationMai",
        "documentation": {}
    }
]