[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "geopandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "geopandas",
        "description": "geopandas",
        "detail": "geopandas",
        "documentation": {}
    },
    {
        "label": "figure",
        "importPath": "bokeh.plotting",
        "description": "bokeh.plotting",
        "isExtraImport": true,
        "detail": "bokeh.plotting",
        "documentation": {}
    },
    {
        "label": "show",
        "importPath": "bokeh.plotting",
        "description": "bokeh.plotting",
        "isExtraImport": true,
        "detail": "bokeh.plotting",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "directory = './assignment1 data'\n# List of file names based on the naming pattern\nfile_names = [f'stats_crashes_{year}{month:02d}_overview.csv' for year in [2021] for month in range(6,13)]\n# Initialize an empty list to store DataFrames\ndataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "file_names",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "file_names = [f'stats_crashes_{year}{month:02d}_overview.csv' for year in [2021] for month in range(6,13)]\n# Initialize an empty list to store DataFrames\ndataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails\n        df = pd.read_csv(file_path, encoding='utf-16')\n        dataframes.append(df)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "dataframes",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "dataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails\n        df = pd.read_csv(file_path, encoding='utf-16')\n        dataframes.append(df)\n    except UnicodeDecodeError:\n        # Fall back to UTF-8 or another encoding as needed",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "crashes_merged",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "crashes_merged = pd.concat(dataframes, ignore_index=True)\n# Convert the 'Date' column to datetime format\ncrashes_merged['Date'] = pd.to_datetime(crashes_merged['Date'])\n# Sort the DataFrame by the 'Date' column\ncrashes_merged = crashes_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'crashes_merged.csv')\ncrashes_merged.to_csv(merged_file_path, index=False)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "crashes_merged['Date']",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "crashes_merged['Date'] = pd.to_datetime(crashes_merged['Date'])\n# Sort the DataFrame by the 'Date' column\ncrashes_merged = crashes_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'crashes_merged.csv')\ncrashes_merged.to_csv(merged_file_path, index=False)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "crashes_merged",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "crashes_merged = crashes_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'crashes_merged.csv')\ncrashes_merged.to_csv(merged_file_path, index=False)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "merged_file_path",
        "kind": 5,
        "importPath": "crashes_data_scrubber.py",
        "description": "crashes_data_scrubber.py",
        "peekOfCode": "merged_file_path = os.path.join(\"./merged_data\", 'crashes_merged.csv')\ncrashes_merged.to_csv(merged_file_path, index=False)",
        "detail": "crashes_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "delete_columns",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def delete_columns(df, columns_to_delete):\n    # Check if the specified columns exist in the DataFrame before attempting deletion\n    existing_columns = set(df.columns)\n    columns_to_delete = [col for col in columns_to_delete if col in existing_columns]\n    if columns_to_delete:\n        df.drop(columns=columns_to_delete, inplace=True)\n        print(\"Specified columns deleted successfully.\")\n    else:\n        print(\"No specified columns found for deletion.\")\n    return df",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "map_currency_conversion_rates",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def map_currency_conversion_rates(df):\n    required_columns = [\n        'Buyer Currency', \n        'Currency Conversion Rate', \n        'Merchant Currency'\n    ]\n    currency_conversion_to_euro = {}\n    # Check if all required columns are in the DataFrame\n    if all(column in df.columns for column in required_columns) and 'EUR' in df['Merchant Currency'].unique():\n        # Iterate over each row in the DataFrame",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "standardize_column_names",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def standardize_column_names(df, column_mapping):\n    standardized_columns = {}\n    for col in df.columns:\n        standardized_name = column_mapping.get(col, col)  # Get the standardized name if it exists\n        standardized_columns[col] = standardized_name\n    df.rename(columns=standardized_columns, inplace=True)\n    return df\ndef filter_function(file_path, product_id, column_mapping):\n    dtype = {'Amount (Merchant Currency)': float}\n    df = pd.read_csv(file_path, dtype=dtype)",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "filter_function",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def filter_function(file_path, product_id, column_mapping):\n    dtype = {'Amount (Merchant Currency)': float}\n    df = pd.read_csv(file_path, dtype=dtype)\n    df = standardize_column_names(df, column_mapping)  # Standardize column names here\n    filtered_df = df[df['Product ID'].str.contains(product_id)]  # Use the standardized column name\n    return filtered_df\ndef process_data(df):\n    df['Date'] = df['Date'].apply(parser.parse)  # Make sure 'Date' is the standardized column name\n    # Additional preprocessing steps can be added here\n    return df",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "process_data",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def process_data(df):\n    df['Date'] = df['Date'].apply(parser.parse)  # Make sure 'Date' is the standardized column name\n    # Additional preprocessing steps can be added here\n    return df\ndirectory = '.\\\\assignment1 data'\nproduct_id = 'com.vansteinengroentjes.apps.ddfive'\ncolumn_mapping = {\n    'Description': 'Transaction ID',\n    'Order Number': 'Transaction ID',\n    'Transaction Date': 'Date',",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "convert_charged_amount",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def convert_charged_amount(df, currency_conversion_to_euro):\n    # Check if \"Currency of Sale\" and \"Charged Amount\" columns are in the DataFrame\n    if 'Currency of Sale' in df.columns and 'Charged Amount' in df.columns:\n        # Convert \"Charged Amount\" based on \"Currency of Sale\" using the conversion rates\n        df['Charged Amount'] = df.apply(lambda row: round((float(row['Charged Amount'].replace(',', '')) if isinstance(row['Charged Amount'], str) else row['Charged Amount']) * currency_conversion_to_euro.get(row['Currency of Sale'], 1), 2), axis=1)\n        print(\"Charged Amount conversion completed.\")\n    else:\n        print(\"Required columns for Charged Amount conversion are not present. Skipping conversion.\")\ndef merge_columns(df):\n    # Check if both columns exist in the DataFrame before attempting merge",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merge_columns",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def merge_columns(df):\n    # Check if both columns exist in the DataFrame before attempting merge\n    if 'Charged Amount' in df.columns and 'Amount (Merchant Currency)' in df.columns:\n        df['Amount (Merchant Currency)'] = df.apply(lambda row: row['Charged Amount'] if pd.notna(row['Charged Amount']) else row['Amount (Merchant Currency)'], axis=1)\n        print(\"Columns merged successfully.\")\n    if 'Financial Status' in df.columns and 'Transaction Type' in df.columns:\n        df['Transaction Type'] = df.apply(lambda row: 'Charge' if row['Financial Status'] == 'Charged' else row['Transaction Type'], axis=1)\n        print(\"Columns merged successfully.\")\n    else:\n        print(\"Required columns for merging are not present.\")",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "filter_transaction_type",
        "kind": 2,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "def filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")\n    else:\n        print(\"Transaction Type column not found. Skipping filtering.\")\n    return df\n# # Before saving the merged file, apply the filter function\nmerged_df = filter_transaction_type(merged_df)\n# Save the merged DataFrame to a new CSV file",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "directory = '.\\\\assignment1 data'\nproduct_id = 'com.vansteinengroentjes.apps.ddfive'\ncolumn_mapping = {\n    'Description': 'Transaction ID',\n    'Order Number': 'Transaction ID',\n    'Transaction Date': 'Date',\n    'Order Charged Date': 'Date',\n    'Transaction Time': 'Timestamp',\n    'Order Charged Timestamp': 'Timestamp',\n    'Tax Type': 'Tax Status',",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "product_id",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "product_id = 'com.vansteinengroentjes.apps.ddfive'\ncolumn_mapping = {\n    'Description': 'Transaction ID',\n    'Order Number': 'Transaction ID',\n    'Transaction Date': 'Date',\n    'Order Charged Date': 'Date',\n    'Transaction Time': 'Timestamp',\n    'Order Charged Timestamp': 'Timestamp',\n    'Tax Type': 'Tax Status',\n    'Product id': 'Product ID',",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "column_mapping",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "column_mapping = {\n    'Description': 'Transaction ID',\n    'Order Number': 'Transaction ID',\n    'Transaction Date': 'Date',\n    'Order Charged Date': 'Date',\n    'Transaction Time': 'Timestamp',\n    'Order Charged Timestamp': 'Timestamp',\n    'Tax Type': 'Tax Status',\n    'Product id': 'Product ID',\n    'Product ID': 'Product ID',",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "processed_files",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "processed_files = os.listdir(save_directory)\nall_dfs = []  # List to store all DataFrames\nfor file in processed_files:\n    if file.endswith('_processed.csv'):  # Ensure to only include processed files\n        file_path = os.path.join(save_directory, file)\n        df = pd.read_csv(file_path)\n        all_dfs.append(df)\n# Concatenate all DataFrames in the list\nmerged_df = pd.concat(all_dfs, ignore_index=True)\ndef convert_charged_amount(df, currency_conversion_to_euro):",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "all_dfs",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "all_dfs = []  # List to store all DataFrames\nfor file in processed_files:\n    if file.endswith('_processed.csv'):  # Ensure to only include processed files\n        file_path = os.path.join(save_directory, file)\n        df = pd.read_csv(file_path)\n        all_dfs.append(df)\n# Concatenate all DataFrames in the list\nmerged_df = pd.concat(all_dfs, ignore_index=True)\ndef convert_charged_amount(df, currency_conversion_to_euro):\n    # Check if \"Currency of Sale\" and \"Charged Amount\" columns are in the DataFrame",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_df = pd.concat(all_dfs, ignore_index=True)\ndef convert_charged_amount(df, currency_conversion_to_euro):\n    # Check if \"Currency of Sale\" and \"Charged Amount\" columns are in the DataFrame\n    if 'Currency of Sale' in df.columns and 'Charged Amount' in df.columns:\n        # Convert \"Charged Amount\" based on \"Currency of Sale\" using the conversion rates\n        df['Charged Amount'] = df.apply(lambda row: round((float(row['Charged Amount'].replace(',', '')) if isinstance(row['Charged Amount'], str) else row['Charged Amount']) * currency_conversion_to_euro.get(row['Currency of Sale'], 1), 2), axis=1)\n        print(\"Charged Amount conversion completed.\")\n    else:\n        print(\"Required columns for Charged Amount conversion are not present. Skipping conversion.\")\ndef merge_columns(df):",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "currency_conversion_to_euro",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "currency_conversion_to_euro = map_currency_conversion_rates(merged_df)  # Assuming merged_df is your merged DataFrame\nif currency_conversion_to_euro:\n    convert_charged_amount(merged_df, currency_conversion_to_euro)\nmerged_df = merge_columns(merged_df)\ncolumns_to_delete = ['Timestamp', 'Tax Status', 'Refund Type', 'Financial Status','Product Type','Hardware', 'Buyer State', 'Buyer Currency', 'Amount (Buyer Currency)','Currency Conversion Rate', 'Merchant Currency', 'Base Plan ID', 'Offer ID','Device Model',\t'Currency of Sale'\t,'Item Price',\t'Taxes Collected','Charged Amount',\t'City of Buyer',\t'State of Buyer'  ]  # Specify columns to delete here  # noqa: E999\nmerged_df = delete_columns(merged_df, columns_to_delete)  # Update merged_df with the result of delete_columns\ndef filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_df = merge_columns(merged_df)\ncolumns_to_delete = ['Timestamp', 'Tax Status', 'Refund Type', 'Financial Status','Product Type','Hardware', 'Buyer State', 'Buyer Currency', 'Amount (Buyer Currency)','Currency Conversion Rate', 'Merchant Currency', 'Base Plan ID', 'Offer ID','Device Model',\t'Currency of Sale'\t,'Item Price',\t'Taxes Collected','Charged Amount',\t'City of Buyer',\t'State of Buyer'  ]  # Specify columns to delete here  # noqa: E999\nmerged_df = delete_columns(merged_df, columns_to_delete)  # Update merged_df with the result of delete_columns\ndef filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")\n    else:\n        print(\"Transaction Type column not found. Skipping filtering.\")\n    return df",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "columns_to_delete",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "columns_to_delete = ['Timestamp', 'Tax Status', 'Refund Type', 'Financial Status','Product Type','Hardware', 'Buyer State', 'Buyer Currency', 'Amount (Buyer Currency)','Currency Conversion Rate', 'Merchant Currency', 'Base Plan ID', 'Offer ID','Device Model',\t'Currency of Sale'\t,'Item Price',\t'Taxes Collected','Charged Amount',\t'City of Buyer',\t'State of Buyer'  ]  # Specify columns to delete here  # noqa: E999\nmerged_df = delete_columns(merged_df, columns_to_delete)  # Update merged_df with the result of delete_columns\ndef filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")\n    else:\n        print(\"Transaction Type column not found. Skipping filtering.\")\n    return df\n# # Before saving the merged file, apply the filter function",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_df = delete_columns(merged_df, columns_to_delete)  # Update merged_df with the result of delete_columns\ndef filter_transaction_type(df):\n    if 'Transaction Type' in df.columns:\n        df = df[df['Transaction Type'] == 'Charge']\n        print(\"Filtered on Transaction Type: Charge.\")\n    else:\n        print(\"Transaction Type column not found. Skipping filtering.\")\n    return df\n# # Before saving the merged file, apply the filter function\nmerged_df = filter_transaction_type(merged_df)",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_df = filter_transaction_type(merged_df)\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\".\\\\merged_data\", 'sales_merged.csv')\nmerged_df.to_csv(merged_file_path, index=False)\nprint(f'Merged file saved to: {merged_file_path}')",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "merged_file_path",
        "kind": 5,
        "importPath": "sales_data_scrubber",
        "description": "sales_data_scrubber",
        "peekOfCode": "merged_file_path = os.path.join(\".\\\\merged_data\", 'sales_merged.csv')\nmerged_df.to_csv(merged_file_path, index=False)\nprint(f'Merged file saved to: {merged_file_path}')",
        "detail": "sales_data_scrubber",
        "documentation": {}
    },
    {
        "label": "directory",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "directory = './assignment1 data'\n# List of file names based on the naming pattern\nfile_names = [f'stats_ratings_{year}{month:02d}_country.csv' for year in [2021] for month in range(6,13)]\n# Initialize an empty list to store DataFrames\ndataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "file_names",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "file_names = [f'stats_ratings_{year}{month:02d}_country.csv' for year in [2021] for month in range(6,13)]\n# Initialize an empty list to store DataFrames\ndataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails\n        df = pd.read_csv(file_path, encoding='utf-16')\n        dataframes.append(df)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "dataframes",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "dataframes = []\n# Loop through the file names, read each file into a DataFrame, and append it to the list\nfor file_name in file_names:\n    file_path = os.path.join(directory, file_name)\n    try:\n        # Try reading with UTF-16 encoding if UTF-8 fails\n        df = pd.read_csv(file_path, encoding='utf-16')\n        dataframes.append(df)\n    except UnicodeDecodeError:\n        # Fall back to UTF-8 or another encoding as needed",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "country_stats_merged",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "country_stats_merged = pd.concat(dataframes, ignore_index=True)\n# Convert the 'Date' column to datetime format\ncountry_stats_merged['Date'] = pd.to_datetime(country_stats_merged['Date'])\n# Sort the DataFrame by the 'Date' column\ncountry_stats_merged = country_stats_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'country_stats_merged.csv')\ncountry_stats_merged.to_csv(merged_file_path, index=False)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "country_stats_merged['Date']",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "country_stats_merged['Date'] = pd.to_datetime(country_stats_merged['Date'])\n# Sort the DataFrame by the 'Date' column\ncountry_stats_merged = country_stats_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'country_stats_merged.csv')\ncountry_stats_merged.to_csv(merged_file_path, index=False)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "country_stats_merged",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "country_stats_merged = country_stats_merged.sort_values(by='Date')\n# Save the merged DataFrame to a new CSV file\nmerged_file_path = os.path.join(\"./merged_data\", 'country_stats_merged.csv')\ncountry_stats_merged.to_csv(merged_file_path, index=False)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    },
    {
        "label": "merged_file_path",
        "kind": 5,
        "importPath": "stats_country_data_scrubber.py",
        "description": "stats_country_data_scrubber.py",
        "peekOfCode": "merged_file_path = os.path.join(\"./merged_data\", 'country_stats_merged.csv')\ncountry_stats_merged.to_csv(merged_file_path, index=False)",
        "detail": "stats_country_data_scrubber.py",
        "documentation": {}
    }
]